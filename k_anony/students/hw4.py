""" 
Class: CS 181R
Week 7 - Data Privacy and Anonymity
Homework 4
Name:
"""
import pandas as pd
import numpy as np
import os

df = pd.read_csv('data/adult.data')

'''
Question1:  Use pandas to explore the data set from 1994 Census database. 
            How many rows are there in this data set?  
            Add column names to this data set. The list of column names are: ['age', 'workclass', 
            'fnlwgt', 'education', 'education_num', 'marital_status', 'moving', 'relationship', 
            'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country','income']
            Is there any personal Identifiable information in the data set?
            Is there any quasi-identifier information according to Sweeney's defination?
            Can you find possible quasi-identifier among the columns? Why are they?

            Write some codes after TODO. Then write your response in a seperate file and save it as hw4.pdf.
'''

# TODO: Add column names to df. How many rows are there in this data set? 


# TODO      : Is there any personal Identifiable information in the data set?
#           Is there any quasi-identifier information according to Sweeney's defination?
#           Can you find possible quasi-identifier among the columns? 
#           Why do you think they can be quasi-identifier?
#           Hint: use value_counts() to observe how unique a values is for each column. Column with more unique
#               values are more likely to be used as quasi-identifier.




'''
Question 2: Your supervisor believes the information in ['fnlwgt', 'education', 'relationship', 
            'capital_gain', 'capital_loss', 'hours_per_week'] are not necessary for your analysis.
            Use suppression technique to de-idenitify this data set. Name the new data frame 
            variable 'suppressed' and save it as 'suppressed.csv' without a header, without index. 
            How many rows are unique in the 'suppressed' data set? 
'''
# TODO: Use suppression technique to de-idenitify this data set. 
#       Then save the new data set under data directory as 'suppressed.csv' without a header, without index.
suppressed = 


# TODO: How many rows in suppressed data set are unique? Name new dataframe as unique
unique = 


'''
Question 3: Suppose now you have a sensitive dataframe of 10,000 rows named as "link_attack.csv",
            which contains personal identifiable information. Take a look at the head of this attack data,
            perform a link attack and to re-identify people's name, ssn, race, and salary. You can use 
            ['age',  'sex, 'native_country'] as quasi-identifier. How many people can you identify?
 
'''
link_attack = pd.read_csv('data/link_attack.csv')
# TODO: your code here
merged = 

merged_unique = 

'''
Question 4: Consider the definiaiton of k-anonymity, write a function to decide if 
            a data set is k-anonymous for a list of quasi-identifier. Then test if 
            this data set adult.csv is 2 anonymous with ['age', 'sex','native_country']
            being quasi-identifiers
            Hint: method 1: use df.iterrows() to write for loop, or 
                  method 2: use map() to sythesize columns to string and to compare strings.
                  and there are more methods to explore...
'''
qsi = ['age', 'sex', 'native_country']
def is_k_anonymous(k, df, qsi):
    '''
    k: a constant to descide if a data set is k anonymous
    df: the data frame of interest
    qsi: a list of quasi-identifier
    return: True if df is k-anonymous, False if not
    '''
   # TODO: your code here
   return True



'''
Question 5: Now we wish to generalize the informations in adult.csv to make it k-anonymous while minimising
            the lose of information as little as possible. This problem turns out to be NP-Hard, which means 
            there is no polynomial algorithm to solve it. However, a compariably fast algorithm can solve it
            sub-optimal. The detail of this algorithm can be found at: https://github.com/qiyuangong/Mondrian
            Read through it, and use this package to make this data set 2-anonymous.
'''
cmd = 'python3 anonymizer.py s a 2'

# TODO: Use os module to run cmd command. 


# TODO: Read the anonymized data generated by this Mondrian implementation and save it in anony variable.
#        Then add column names ['age', 'workclass',  'education_num','marital_status', 'moving', 'race', 
#       'sex','native_country','income'] and observe this data set.
anony = 


# TODO: Test if it is k-anonymous using the function in Question 3 and same quasi-identifier. 
#       How many rows in this data set are unique now? We can call the non-duplicate data set
#       as unique anony.

unique_anony = 



'''
Question 6: Use the anonymized data set, analyze what percentage of male and female has income 
            less than 50k? Compare the result with the original datase 'adult.data'.
'''



def main():
    # test 1
    assert np.array_equal(df.columns, ['age', 'workclass', 
            'fnlwgt', 'education', 'education_num', 'marital_status', 'moving', 'relationship', 
            'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country','income']) == True
    # test 2
    assert np.array_equal(suppressed.columns, ['age', 'workclass', 'education_num',
            'marital_status', 'moving', 'race', 'sex', 'native_country','income'] ) == True

    assert unique.shape[0] == 17047

    # test 3
    assert merged_unique.shape[0] == 287

    # test 4
    assert is_k_anonymous(2, suppressed, qsi) == False

    two_anon = pd.DataFrame(
    [
        ['*', 'Storm',34,'Black'],
        ['John','*','*','*'],
        ['*', 'Storm',34,'Black'],
        ['John','*','*','*']
    ],
    columns = ['First','Last','age','race']
)
    assert is_k_anonymous(2, two_anon, ['First','Last','age','race']) == True

    # test 5
    assert is_k_anonymous(2,anony, qsi) == True
    assert unique_anony.shape[0] == 0

    # test 6
    # print(df.groupby('sex').get_group(' Male')['income'].value_counts().tolist())
    # print(df.groupby('sex').groups.keys())
    # assert anony.groupby('sex').get_group('Male')['income'].value_counts().tolist()[0] == 13685
    # assert df.groupby('sex').get_group(' Male')['income'].value_counts().tolist()[0] == 13685



if __name__ == "__main__":
    main()
